# 1. Neural Networks Made Easy

This tutorial by Ophir Tanz and Cambron Carter is a fun high-level math-free tutorial on neural networks and in particular, goes into more depth on convolutional neural networks - a form of neural network with multiple layers of processing that forms the basis for many deep learning systems today (see the Deep Learning lecture for more details).

Carter, C., & Tanz, O. (2017, April 13). Neural networks made easy. Retrieved May 10, 2017, from: 

https://techcrunch.com/2017/04/13/neural-networks-made-easy/

---

# 2. Play with Neural Networks: TensorFlow Playground

This neural network simulation by Daniel Smilkov and Shan Carter  lets you play with neural networks in your browser. See the effect of different parameter settings and network configurations on a choice of difficult example classification problems.  

The "output" on the right shows the "training loss" and "test loss".  Loss is an evaluation metric that is related to the number of errors made for each example on the training or test set - so lower loss numbers are better.  (In technical terms, for neural networks the loss is usually negative log-likelihood for classification, and residual sum of squares for regression.)

To show decision boundaries more clearly, along with the test data, click the two checkboxes marked "Show test data" and "Discretize output" in the lower right of the window.

To access the simulation, click here:

**http://playground.tensorflow.org/**

---

# 3. Deep Learning in a Nutshell: Core Concepts

This self-contained tutorial by Tim Dettmers covers the key high-level concepts of deep learning and reinforces the basic concepts we covered in the Neural Networks and Deep Learning lectures.  There are multiple parts - Part 1 is less technical while Parts 2-4 go into more detail on algorithms.

The link to access Part 1 is here:

https://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/

Deep Learning in a Nutshell: Core Concepts. (2016, September 08). Retrieved May 10, 2017.

---

# 4. Assisting Pathologists in Detecting Cancer with Deep Learning

This short article is an example of how deep learning is being used in healthcare.

Assisting Pathologists in Detecting Cancer with Deep Learning
https://research.googleblog.com/2017/03/assisting-pathologists-in-detecting.html

Posted by Martin Stumpe (Technical Lead) and Lily Peng (Product Manager), Google Research Blog 

---

# 5. The Treachery of Leakage

This fun, less-technical read from Colin Fraser reinforces the material in the Data Leakage lecture to provide further explanation and examples on detecting and avoiding data leakage in your machine learning applications.

Here's the link to the article:

https://medium.com/@colin.fraser/the-treachery-of-leakage-56a2d7c4e931

---

# 6. Leakage in Data Mining: Formulation, Detection, and Avoidance

If you want an example in more depth of how data scientists are exploring ways to detect and avoid data leakage, this technical article proposes one approach: a two-stage process based on "legitimacy tags".

If you're just interested in getting a little more background on the problem along with interesting examples, Sections 1 and 2 (Introduction and Related Work) are also useful to read on their own.

http://www.cs.umb.edu/~ding/history/470_670_fall_2011/papers/cs670_Tran_PreferredPaper_LeakingInDataMining.pdf

Kaufman, S., Rosset, S., & Perlich, C. (2011). Leakage in data mining
. Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '11. doi:10.1145/2020408.2020496

---

# 7. Data Leakage Example: The ICML 2013 Whale Challenge

In 2013 a machine learning competition offered a prize for the most accurate detection of right whale calls based on audio data.  The organizers soon discovered data leakage problems in the first release of the dataset, and this article explains what happened.  It's a short but interesting article that serves as an excellent example of how subtle or not-so-subtle leakage can occur in specific features.

https://www.kaggle.com/c/the-icml-2013-whale-challenge-right-whale-redux/discussion/4865#25839#post25839

---

# 8. Rules of Machine Learning: Best Practices for ML Engineering

This optional reading is intended mainly for software engineers who want to build and deploy machine learning applications in production - especially at scale. The only background knowledge required are the basic machine learning concepts we've covered so far in this course.  Written by Google's Dr. Martin Zinkevich,  it walks through a set of software engineering best practices for designing and deploying machine learning in software systems - based on years of practical experience at Google.

http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf

---

# 9. How to Use t-SNE Effectively

Wattenberg, et al., "How to Use t-SNE Effectively", Distill, 2016. http://doi.org/10.23915/distill.00002

http://distill.pub/2016/misread-tsne/#citation

---
 # 10. How Machines Make Sense of Big Data: an Introduction to Clustering Algorithms

Gleesen, Peter. "How Machines Make Sense of Big Data: an Introduction to Clustering Algorithms", freeCodeCamp, 2017. 

https://medium.freecodecamp.com/how-machines-make-sense-of-big-data-an-introduction-to-clustering-algorithms-4bd97d4fbaba



