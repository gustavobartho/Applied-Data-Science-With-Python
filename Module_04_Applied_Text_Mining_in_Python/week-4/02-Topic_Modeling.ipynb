{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling\n",
    "\n",
    "### **What is Topic Modeling?**\n",
    "* A coarse-level analysis of what's in a text collection\n",
    "* **Topic**: the subject (theme) of a discourse\n",
    "* Topics are represented as a word distribution\n",
    "* A document is assumed to be a mixture of topics\n",
    "* What's known:\n",
    "    * The text collection or corpus\n",
    "    * The number of topics\n",
    "* What's not known:\n",
    "    * The actual topics\n",
    "    * Topic distribution for each document\n",
    "* Essentially, topic modeling is a text clustering problem - documents and words clustered simultaneously\n",
    "* Different topic modeling approaches are available:\n",
    "    * Probabilistic Latent Semantic Analysis (PLSA)\n",
    "    * Latent Dirichlet Allocation\n",
    "\n",
    "### **Latent Dirichlet Allocation (LDA)**\n",
    "* Generative model for a document `d`\n",
    "    * Choose length of document `d`  \n",
    "    * Choose a mixture of topics for document `d` \n",
    "    * Use a topic's multinomial distribution to output words to fill that topic's quota\n",
    "\n",
    "### **Topic Modeling in Practice**\n",
    "* How many topics? - Finding or even guessing the number of topics is hard\n",
    "* Interpreting the topics\n",
    "    * Topics are just word distributions\n",
    "    * Making sense of words / generating labels is subjective\n",
    "\n",
    "### **Important Concepts**\n",
    "* Topic Modeling is a great tool for exploratory text analysis - What are the documents (tweets, reviews, news, articles, ...) about?\n",
    "* Many tools available to do it effortlessly in Python\n",
    "\n",
    "### **Working with LDA in Python**\n",
    "* Many packages available such as gensim and lda\n",
    "* Pre-processing text:\n",
    "    * Tokenize, normalize (lowercase)\n",
    "    * Stop word removal\n",
    "    * Stemming\n",
    "* Convert tokenized documents to a document-term matrix\n",
    "* Build LDA models on the doc-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.width', 1000)\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# sample the news data stratifying by topic\n",
    "news_data = (\n",
    "    pd.read_csv('../datasets/News_Classification/train.csv')\n",
    "    .groupby('Class Index', group_keys=False)\n",
    "    .apply(lambda x: x.sample(n=50))['Description']\n",
    "    .str.lower()\n",
    "    .replace(r'\\(.*\\)', '', regex=True)\n",
    "    .replace(r'[^a-zA-Z\\ ]', '', regex=True)\n",
    "    .to_list()\n",
    ")\n",
    "\n",
    "#Pre-process data\n",
    "for i, text in enumerate(news_data):\n",
    "    token_text = word_tokenize(text)\n",
    "    news_data[i] = [word for word in token_text if word not in [*stopwords.words('english'), 'said', 'us', 'ap', 'one', 'new']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005*\"security\" + 0.005*\"game\" + 0.004*\"southern\" + 0.004*\"day\" + 0.004*\"european\"\n",
      "0.007*\"president\" + 0.007*\"olympic\" + 0.005*\"first\" + 0.005*\"committee\" + 0.004*\"home\"\n",
      "0.009*\"pm\" + 0.005*\"three\" + 0.005*\"china\" + 0.005*\"search\" + 0.004*\"st\"\n",
      "0.006*\"nation\" + 0.005*\"sunday\" + 0.005*\"iraq\" + 0.004*\"last\" + 0.004*\"today\"\n",
      "0.005*\"software\" + 0.004*\"companies\" + 0.004*\"would\" + 0.004*\"state\" + 0.004*\"court\"\n",
      "0.006*\"president\" + 0.005*\"first\" + 0.004*\"last\" + 0.004*\"million\" + 0.004*\"corp\"\n",
      "0.006*\"group\" + 0.006*\"wednesday\" + 0.005*\"thursday\" + 0.005*\"yesterday\" + 0.005*\"prime\"\n",
      "0.009*\"microsoft\" + 0.006*\"state\" + 0.006*\"first\" + 0.004*\"may\" + 0.004*\"company\"\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "num_topics = 8\n",
    "\n",
    "dictionary = Dictionary(news_data)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in news_data]\n",
    "ldamodel = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=50)\n",
    "for i in range(num_topics): print(ldamodel.print_topic(topicno=i, topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Important Concepts**\n",
    "* Topic modeling is an exploratory tool frequently used for text mining\n",
    "* Latent Dirichlet Allocation is a generative model used extensively for modeling large text corpora\n",
    "* LDA can also be used as a feature selection technique for text classification and other tasks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
